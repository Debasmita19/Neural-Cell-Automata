{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP+8jg6OCw2lsrXTicM29gq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Debasmita19/Neural-Cell-Automata/blob/main/Untitled0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A_sgbyh24p_H"
      },
      "source": [],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WUK0eyROxeX0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ib4SCHbewEYp"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "gDtnexuMwKh2",
        "outputId": "55822891-0d17-440b-b37b-ca9f37a77faf"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndentationError",
          "evalue": "unindent does not match any outer indentation level (<tokenize>, line 19)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<tokenize>\"\u001b[0;36m, line \u001b[0;32m19\u001b[0m\n\u001b[0;31m    self.update_module[2].weight.zero_()\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unindent does not match any outer indentation level\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aOdNLkt-xf9s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "\n",
        "class CAModel(nn.Module):\n",
        "    \"\"\"Cell automata model.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    n_channels : int\n",
        "        Number of channels of the grid.\n",
        "\n",
        "    hidden_channels : int\n",
        "        Hidden channels that are related to the pixelwise 1x1 convolution.\n",
        "\n",
        "    fire_rate : float\n",
        "        Number between 0 and 1. The lower it is the more likely it is for\n",
        "        cells to be set to zero during the `stochastic_update` process.\n",
        "\n",
        "    device : torch.device\n",
        "        Determines on what device we perform all the computations.\n",
        "\n",
        "    Attributes\n",
        "    ----------\n",
        "    update_module : nn.Sequential\n",
        "        The only part of the network containing trainable parameters. Composed\n",
        "        of 1x1 convolution, ReLu, and 1x1 convolution.\n",
        "\n",
        "    filters : torch.Tensor\n",
        "        Constant tensor of shape `(3 * n_channels, 1, 3, 3)`.\n",
        "    \"\"\"\n",
        "    def __init__(self, n_channels=16, hidden_channels=128, fire_rate=0.5, device=None):\n",
        "        super().__init__()\n",
        "\n",
        "        # Update to use passed fire_rate value\n",
        "        self.fire_rate = fire_rate\n",
        "        self.n_channels = n_channels\n",
        "        self.device = device or torch.device(\"cpu\")\n",
        "\n",
        "        # Perceive step\n",
        "        sobel_filter_ = torch.tensor([[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]], device=self.device)\n",
        "        scalar = 8.0\n",
        "\n",
        "        sobel_filter_x = sobel_filter_ / scalar\n",
        "        sobel_filter_y = sobel_filter_.t() / scalar\n",
        "        identity_filter = torch.tensor(\n",
        "                [\n",
        "                    [0, 0, 0],\n",
        "                    [0, 1, 0],\n",
        "                    [0, 0, 0],\n",
        "                ],\n",
        "                dtype=torch.float32,\n",
        "                device=self.device\n",
        "        )\n",
        "        filters = torch.stack(\n",
        "                [identity_filter, sobel_filter_x, sobel_filter_y]\n",
        "        )  # (3, 3, 3)\n",
        "        filters = filters.repeat((n_channels, 1, 1))  # (3 * n_channels, 3, 3)\n",
        "        self.filters = filters[:, None, ...].to(\n",
        "                self.device\n",
        "        )  # (3 * n_channels, 1, 3, 3)\n",
        "\n",
        "        # Update step\n",
        "        self.update_module = nn.Sequential(\n",
        "                nn.Conv2d(\n",
        "                    3 * n_channels,\n",
        "                    hidden_channels,\n",
        "                    kernel_size=1,  # (1, 1)\n",
        "                ),\n",
        "                nn.ReLU(),\n",
        "                nn.Conv2d(\n",
        "                    hidden_channels,\n",
        "                    n_channels,\n",
        "                    kernel_size=1,\n",
        "                    bias=False,\n",
        "                ),\n",
        "        )\n",
        "\n",
        "        # Zero-initialize the final convolution weights\n",
        "        with torch.no_grad():\n",
        "            self.update_module[2].weight.zero_()\n",
        "\n",
        "        self.to(self.device)\n",
        "\n",
        "    def perceive(self, x):\n",
        "        \"\"\"Approximate channelwise gradient and combine with the input.\n",
        "\n",
        "        This is the only place where we include information on the\n",
        "        neighboring cells. However, we are not using any learnable\n",
        "        parameters here.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        x : torch.Tensor\n",
        "            Shape `(n_samples, n_channels, grid_size, grid_size)`.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        torch.Tensor\n",
        "            Shape `(n_samples, 3 * n_channels, grid_size, grid_size)`.\n",
        "        \"\"\"\n",
        "        return nn.functional.conv2d(x, self.filters, padding=1, groups=self.n_channels)\n",
        "\n",
        "    def update(self, x):\n",
        "        \"\"\"Perform update.\n",
        "\n",
        "        Note that this is the only part of the forward pass that uses\n",
        "        trainable parameters.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        x : torch.Tensor\n",
        "            Shape `(n_samples, 3 * n_channels, grid_size, grid_size)`.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        torch.Tensor\n",
        "            Shape `(n_samples, n_channels, grid_size, grid_size)`.\n",
        "        \"\"\"\n",
        "        return self.update_module(x)\n",
        "\n",
        "    @staticmethod\n",
        "    def stochastic_update(x, fire_rate):\n",
        "        \"\"\"Run pixel-wise dropout.\n",
        "\n",
        "        Unlike dropout there is no scaling taking place.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        x : torch.Tensor\n",
        "            Shape `(n_samples, n_channels, grid_size, grid_size)`.\n",
        "\n",
        "        fire_rate : float\n",
        "            Number between 0 and 1. The higher the more likely a given cell\n",
        "            updates.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        torch.Tensor\n",
        "            Shape `(n_samples, n_channels, grid_size, grid_size)`.\n",
        "        \"\"\"\n",
        "        device = x.device\n",
        "\n",
        "        mask = (torch.rand(x[:, :1, :, :].shape, device=device) <= fire_rate).to(device, torch.float32)\n",
        "        return x * mask  # broadcasted over all channels\n",
        "\n",
        "    @staticmethod\n",
        "    def get_living_mask(x):\n",
        "        \"\"\"Identify living cells.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        x : torch.Tensor\n",
        "            Shape `(n_samples, n_channels, grid_size, grid_size)`.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        torch.Tensor\n",
        "            Shape `(n_samples, 1, grid_size, grid_size)` and the\n",
        "            dtype is bool.\n",
        "        \"\"\"\n",
        "        return (\n",
        "            nn.functional.max_pool2d(\n",
        "                x[:, 3:4, :, :], kernel_size=3, stride=1, padding=1\n",
        "            )\n",
        "            > 0.1\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"Run the forward pass.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        x : torch.Tensor\n",
        "            Shape `(n_samples, n_channels, grid_size, grid_size)`.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        torch.Tensor\n",
        "            Shape `(n_sample, n_channels, grid_size, grid_size)`.\n",
        "        \"\"\"\n",
        "        pre_life_mask = self.get_living_mask(x)\n",
        "\n",
        "        y = self.perceive(x)\n",
        "        dx = self.update(y)\n",
        "        dx = self.stochastic_update(dx, fire_rate=self.fire_rate)\n",
        "\n",
        "        x = x + dx\n",
        "\n",
        "        post_life_mask = self.get_living_mask(x)\n",
        "        life_mask = (pre_life_mask & post_life_mask).to(torch.float32)\n",
        "\n",
        "        return x * life_mask\n"
      ],
      "metadata": {
        "id": "_Vtd_iT8xgDd"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "0rjclUrJx6BX",
        "outputId": "a516f117-8120-4304-8266-26a061b604c6"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "incomplete input (<ipython-input-19-b024a1aaa6a9>, line 1)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-19-b024a1aaa6a9>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    '''initial_grid = torch.rand((batch_size, n_channels, grid_size, grid_size), device=device)\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m incomplete input\n"
          ]
        }
      ]
    }
  ]
}